# -*- coding: utf-8 -*-
"""Emotion_Recognition.ipynb

Automatically generated by Colaboratory.

Original file is located at
    https://colab.research.google.com/drive/1pmpHp6A9j2P-xrXpCQEJfK-NONFdVoTR
"""

from google.colab import drive
drive.mount('/content/drive')

from IPython import get_ipython;
get_ipython().magic('reset -sf')

import tensorflow_datasets as tfds

from tensorflow.keras.preprocessing.image import ImageDataGenerator

train_datagen = ImageDataGenerator(rescale=1./255)
test_datagen = ImageDataGenerator(rescale=1./255)

batch_size = 32
image_size = 48

train_generator = train_datagen.flow_from_directory(
    '/content/drive/MyDrive/FER-2013/train',
    target_size=(image_size, image_size),
    batch_size=batch_size,
    class_mode='categorical'
)

test_generator = test_datagen.flow_from_directory(
    '/content/drive/MyDrive/FER-2013/test',
    target_size=(image_size, image_size),
    batch_size=batch_size,
    class_mode='categorical',
    shuffle=False  # No mezclar las imágenes de prueba
)

from tensorflow.keras.models import Sequential
from tensorflow.keras.layers import Conv2D, MaxPooling2D, Flatten, Dense

model = Sequential([
    Conv2D(16, (3, 3), activation='relu', input_shape=(image_size, image_size, 3)),
    MaxPooling2D((2, 2)),
    Conv2D(64, (3, 3), activation='relu'),
    MaxPooling2D((2, 2)),
    Conv2D(128, (3, 3), activation='relu'),
    MaxPooling2D((2, 2)),
    Flatten(),
    Dense(64, activation='relu'),   #Capa densa de 64 neuronas
    Dense(7, activation='softmax')
])

model.compile(optimizer='adam',
              loss='categorical_crossentropy',
              metrics=['accuracy'])

epochs = 3

history = model.fit(
    train_generator,
    epochs=epochs,
    validation_data=test_generator
)

test_loss, test_acc = model.evaluate(test_generator)
print('Precisión en el conjunto de prueba:', test_acc)

import numpy as np
from sklearn.metrics import confusion_matrix, classification_report
import seaborn as sns
import matplotlib.pyplot as plt

predictions = model.predict(test_generator)
predicted_labels = np.argmax(predictions, axis=1)
true_labels = test_generator.classes
confusion = confusion_matrix(true_labels, predicted_labels)
print(confusion)
report = classification_report(true_labels, predicted_labels, target_names=test_generator.class_indices)
print(report)

confusion = confusion_matrix(true_labels, predicted_labels)
plt.figure(figsize=(8, 6))
sns.set(font_scale=1.2)

class_names = list(test_generator.class_indices.keys())
print(class_names)

sns.heatmap(confusion, annot=True, fmt='g', cmap='Blues', cbar=False,
            xticklabels=class_names,
            yticklabels=class_names)

model.save('Emotion_Recognition_JavAlm.h5')

import gradio as gr
from tensorflow.keras.models import load_model
import numpy as np
from tensorflow.keras.applications.resnet50 import preprocess_input
from tensorflow.keras.preprocessing.image import load_img, img_to_array


model = load_model('/content/Emotion_Recognition_JavAlm.h5')


def predict_image(input_image):
    img = load_img(input_image, target_size=(48, 48))
    img_array = img_to_array(img)
    img_array = np.expand_dims(img_array, axis=0)
    img_array = preprocess_input(img_array)
    prediction = model.predict(img_array)
    class_index = np.argmax(prediction)
    return {'predicción': class_name}

# Crear la interfaz de Gradio
iface = gr.Interface(
    fn=predict_image,
    inputs="image",
    outputs="json"
)

iface.launch()

img = load_img('/content/retrato-frontal-mujer-rostro-belleza_186202-6146.png', target_size=(48, 48))
img_array = img_to_array(img)
img_array = np.expand_dims(img_array, axis=0)
img_array = preprocess_input(img_array)
prediction = model.predict(img_array)
class_index = np.argmax(prediction)
class_name = class_names[class_index]
print(class_name)